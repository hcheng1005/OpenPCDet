{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "\n",
    "from onnxsim import simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use onnx_graphsurgeon to adjust postprocessing part in the onnx...\n",
      "transpose_node \n",
      " Conv_378 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (625): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_cls.3.weight): (shape=[2, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_cls.3.bias): (shape=[2], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (626): (shape=[1, 2, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_381 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (629): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_reg.3.weight): (shape=[4, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_reg.3.bias): (shape=[4], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (630): (shape=[1, 4, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_384 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (633): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_height.3.weight): (shape=[2, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_height.3.bias): (shape=[2], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (634): (shape=[1, 2, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_387 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (637): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_size.3.weight): (shape=[6, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_size.3.bias): (shape=[6], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (638): (shape=[1, 6, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_390 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (641): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_angle.3.weight): (shape=[4, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_angle.3.bias): (shape=[4], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (642): (shape=[1, 4, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_393 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (645): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_velo.3.weight): (shape=[4, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.0.conv_box.conv_velo.3.bias): (shape=[4], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (646): (shape=[1, 4, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_442 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (695): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_cls.3.weight): (shape=[2, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_cls.3.bias): (shape=[2], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (696): (shape=[1, 2, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_445 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (699): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_reg.3.weight): (shape=[4, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_reg.3.bias): (shape=[4], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (700): (shape=[1, 4, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_448 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (703): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_height.3.weight): (shape=[2, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_height.3.bias): (shape=[2], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (704): (shape=[1, 2, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_451 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (707): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_size.3.weight): (shape=[6, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_size.3.bias): (shape=[6], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (708): (shape=[1, 6, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_454 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (711): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_angle.3.weight): (shape=[4, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_angle.3.bias): (shape=[4], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (712): (shape=[1, 4, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n",
      "transpose_node \n",
      " Conv_457 (Conv)\n",
      "\tInputs: [\n",
      "\t\tVariable (715): (shape=[1, 64, 128, 128], dtype=float32)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_velo.3.weight): (shape=[4, 64, 3, 3], dtype=<class 'numpy.float32'>)\n",
      "\t\tConstant (dense_head.rpn_heads.1.conv_box.conv_velo.3.bias): (shape=[4], dtype=<class 'numpy.float32'>)\n",
      "\t]\n",
      "\tOutputs: [\n",
      "\t\tVariable (716): (shape=[1, 4, 128, 128], dtype=float32)\n",
      "\t]\n",
      "Attributes: OrderedDict([('dilations', [1, 1]), ('group', 1), ('kernel_shape', [3, 3]), ('pads', [1, 1, 1, 1]), ('strides', [1, 1])])\n"
     ]
    }
   ],
   "source": [
    "# SPDX-FileCopyrightText: Copyright (c) 2021 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import onnx\n",
    "import numpy as np\n",
    "import onnx_graphsurgeon as gs\n",
    "\n",
    "@gs.Graph.register()\n",
    "def replace_with_clip(self, inputs, outputs):\n",
    "    for inp in inputs:\n",
    "        inp.outputs.clear()\n",
    "\n",
    "    for out in outputs:\n",
    "        out.inputs.clear()\n",
    "\n",
    "    op_attrs = dict()\n",
    "    op_attrs[\"dense_shape\"] = np.array([496,432])\n",
    "\n",
    "    return self.layer(name=\"PPScatter_0\", op=\"PPScatterPlugin\", inputs=inputs, outputs=outputs, attrs=op_attrs)\n",
    "\n",
    "def loop_node(graph, current_node, loop_time=0):\n",
    "  for i in range(loop_time):\n",
    "    next_node = [node for node in graph.nodes if len(node.inputs) != 0 and len(current_node.outputs) != 0 and node.inputs[0] == current_node.outputs[0]][0]\n",
    "    current_node = next_node\n",
    "  return next_node\n",
    "\n",
    "def simplify_postprocess(onnx_model):\n",
    "  print(\"Use onnx_graphsurgeon to adjust postprocessing part in the onnx...\")\n",
    "  graph = gs.import_onnx(onnx_model)\n",
    "\n",
    "  output_01 = gs.Variable(name=\"11\", dtype=np.float32)\n",
    "  output_02 = gs.Variable(name=\"21\", dtype=np.float32)\n",
    "  output_03 = gs.Variable(name=\"31\", dtype=np.float32)\n",
    "  output_04 = gs.Variable(name=\"41\", dtype=np.float32)\n",
    "  output_05 = gs.Variable(name=\"51\", dtype=np.float32)\n",
    "  output_06 = gs.Variable(name=\"61\", dtype=np.float32)\n",
    "  output_011 = gs.Variable(name=\"12\", dtype=np.float32)\n",
    "  output_021 = gs.Variable(name=\"22\", dtype=np.float32)\n",
    "  output_031 = gs.Variable(name=\"32\", dtype=np.float32)\n",
    "  output_041 = gs.Variable(name=\"42\", dtype=np.float32)\n",
    "  output_051 = gs.Variable(name=\"52\", dtype=np.float32)\n",
    "  output_061 = gs.Variable(name=\"62\", dtype=np.float32)\n",
    "\n",
    "  tmap = graph.tensors()\n",
    "  new_inputs = [tmap[\"voxels\"], tmap[\"voxel_idxs\"], tmap[\"voxel_num\"]]\n",
    "  new_outputs = [output_01, output_02, output_03,output_04, output_05, output_06,\n",
    "                 output_011, output_021, output_031,output_041, output_051, output_061]\n",
    "\n",
    "  for inp in graph.inputs:\n",
    "    if inp not in new_inputs:\n",
    "      inp.outputs.clear()\n",
    "\n",
    "  for out in graph.outputs:\n",
    "    out.inputs.clear()\n",
    "\n",
    "  #  找到链接ConvTranspose的node\n",
    "  first_ConvTranspose_node = [node for node in graph.nodes if node.op == \"ConvTranspose\"][0] \n",
    "  \n",
    "  # print('first_ConvTranspose_node', first_ConvTranspose_node)\n",
    "  # print('first_ConvTranspose_node', first_ConvTranspose_node.outputs[0])\n",
    "  \n",
    "  current_node = first_ConvTranspose_node\n",
    "  for i in range(3):\n",
    "    # print('__________________________________________________________________')\n",
    "    # print(current_node)\n",
    "    for node in graph.nodes: \n",
    "      if len(node.inputs) != 0 and len(current_node.outputs) != 0 :\n",
    "        if node.op == \"Concat\":\n",
    "            if node.inputs[1] == current_node.outputs[0]:\n",
    "              # print([node][0])\n",
    "              next_node = [node][0]\n",
    "        else:\n",
    "            if node.inputs[0] == current_node.outputs[0]:\n",
    "              # print([node][0])\n",
    "              next_node = [node][0]\n",
    "\n",
    "    current_node = next_node\n",
    "    # print(current_node.outputs[0])\n",
    "    \n",
    "  concat_node = current_node\n",
    "  assert concat_node.op == \"Concat\"\n",
    "  # concat_node = loop_node(graph, first_ConvTranspose_node, 3)\n",
    "  # print(concat_node)\n",
    "  # assert concat_node.op == \"Concat\"\n",
    "\n",
    "  conv_node_after_concat = [node for node in graph.nodes if len(node.inputs) != 0 and len(concat_node.outputs) != 0 and node.inputs[0] == concat_node.outputs[0]][0]\n",
    "  # print('conv_node_after_concat \\n', conv_node_after_concat)\n",
    "  \n",
    "  # print(conv_node_after_concat.outputs)\n",
    "  \n",
    "  first_node_after_concat = [node for node in graph.nodes if len(node.inputs) != 0 and len(conv_node_after_concat.outputs) != 0 and node.inputs[0] == conv_node_after_concat.outputs[0]][0]\n",
    "  # print('first_node_after_concat \\n', first_node_after_concat)\n",
    "  # print(len(first_node_after_concat))\n",
    "  \n",
    "  first_node_after_relu = [node for node in graph.nodes if len(node.inputs) != 0 and len(first_node_after_concat.outputs) != 0 and node.inputs[0] == first_node_after_concat.outputs[0]]\n",
    "  # print('first_node_after_concat \\n', first_node_after_relu)\n",
    "  # print(len(first_node_after_relu))\n",
    "\n",
    "  for i in range(len(first_node_after_relu)):\n",
    "    transpose_node = loop_node(graph, first_node_after_relu[i], 2)\n",
    "    print('transpose_node \\n', transpose_node)\n",
    "    assert transpose_node.op == \"Conv\"\n",
    "    transpose_node.outputs = [new_outputs[i]] # 重新设定模型输出节点与位置\n",
    "\n",
    "  graph.inputs = new_inputs\n",
    "  graph.outputs = new_outputs\n",
    "  graph.cleanup().toposort()\n",
    "  \n",
    "  return gs.export_onnx(graph)\n",
    "\n",
    "\n",
    "onnx_raw = onnx.load(\"./pp_simple.onnx\")  # load onnx model\n",
    "# onnx_raw = onnx.load(\"./pointpillar_raw.onnx\") \n",
    "onnx_trim_post = simplify_postprocess(onnx_raw)\n",
    "onnx.save(onnx_trim_post, \"pp_simple1.onnx\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_preprocess(onnx_model):\n",
    "  print(\"Use onnx_graphsurgeon to modify onnx...\")\n",
    "  graph = gs.import_onnx(onnx_model)\n",
    "\n",
    "  tmap = graph.tensors()\n",
    "  # print(tmap)\n",
    "  MAX_VOXELS = tmap[\"voxels\"].shape[0]\n",
    "\n",
    "  # voxels: [V, P, C']\n",
    "  # V is the maximum number of voxels per frame\n",
    "  # P is the maximum number of points per voxel\n",
    "  # C' is the number of channels(features) per point in voxels.\n",
    "  input_new = gs.Variable(name=\"voxels\", dtype=np.float32, shape=(MAX_VOXELS, 32, 10))\n",
    "\n",
    "  # voxel_idxs: [V, 4]\n",
    "  # V is the maximum number of voxels per frame\n",
    "  # 4 is just the length of indexs encoded as (frame_id, z, y, x).\n",
    "  X = gs.Variable(name=\"voxel_idxs\", dtype=np.int32, shape=(MAX_VOXELS, 4))\n",
    "\n",
    "  # voxel_num: [1]\n",
    "  # Gives valid voxels number for each frame\n",
    "  Y = gs.Variable(name=\"voxel_num\", dtype=np.int32, shape=(1,))\n",
    "\n",
    "  first_node_after_pillarscatter = [node for node in graph.nodes if node.op == \"Conv\"][0]\n",
    "\n",
    "  first_node_pillarvfe = [node for node in graph.nodes if node.op == \"MatMul\"][0]\n",
    "\n",
    "  next_node = current_node = first_node_pillarvfe\n",
    "  for i in range(6):\n",
    "    next_node = [node for node in graph.nodes if node.inputs[0] == current_node.outputs[0]][0]\n",
    "    if i == 5:              # ReduceMax\n",
    "      current_node.attrs['keepdims'] = [0]\n",
    "      break\n",
    "    current_node = next_node\n",
    "\n",
    "  last_node_pillarvfe = current_node\n",
    "\n",
    "  #merge some layers into one layer between inputs and outputs as below\n",
    "  graph.inputs.append(Y)\n",
    "  inputs = [last_node_pillarvfe.outputs[0], X, Y]\n",
    "  outputs = [first_node_after_pillarscatter.inputs[0]]\n",
    "  graph.replace_with_clip(inputs, outputs)\n",
    "\n",
    "  # Remove the now-dangling subgraph.\n",
    "  graph.cleanup().toposort()\n",
    "\n",
    "  #just keep some layers between inputs and outputs as below\n",
    "  graph.inputs = [first_node_pillarvfe.inputs[0] , X, Y]\n",
    "  graph.outputs = [tmap[\"1\"], tmap[\"2\"], tmap[\"3\"],tmap[\"4\"], tmap[\"5\"], tmap[\"6\"]]\n",
    "\n",
    "  graph.cleanup()\n",
    "\n",
    "  #Rename the first tensor for the first layer \n",
    "  graph.inputs = [input_new, X, Y]\n",
    "  first_add = [node for node in graph.nodes if node.op == \"MatMul\"][0]\n",
    "  first_add.inputs[0] = input_new\n",
    "\n",
    "  graph.cleanup().toposort()\n",
    "\n",
    "  return gs.export_onnx(graph)\n",
    "\n",
    "\n",
    "onnx_trim_post = simplify_preprocess(onnx_trim_post)\n",
    "onnx.save(onnx_trim_post, \"pp_simple2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
